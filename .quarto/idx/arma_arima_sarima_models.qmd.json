{"title":"ARMA/ARIMA/SARIMA Models","markdown":{"yaml":{"title":"ARMA/ARIMA/SARIMA Models","editor_options":{"chunk_output_type":"inline"},"toc":false},"headingText":"Fitting NYC Arrests Series by Crime","containsRefs":false,"markdown":"\n\n```{r include = FALSE}\nknitr::opts_chunk$set(echo = FALSE)\n```\n\n\n```{r setup, include = FALSE}\nlibrary(reticulate)\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(ggplot2)\nlibrary(forecast)\nlibrary(TSstudio)\nlibrary(tseries)\nlibrary(gridExtra)\nlibrary(kableExtra)\nlibrary(astsa)\nload(\"arrests_ts.Rdata\")\n```\n\n::: panel-tabset\n# Total\n\nWe are fitting a SARIMA model as we saw a clear seasonal component in the previous section. We need to determine the following parameters:\n\n-   p: The order of AR terms.\n-   d: The degree of differencing needed to make the data stationary.\n-   q: The order of MA terms.\n-   P: The seasonal order of AR terms.\n-   D: The seasonal degree of differencing.\n-   Q: The seasonal order of MA terms.\n-   s: The seasonal period.\n\n## ACF and PACF\n\n```{r}\nggtsdisplay(arrests_ts)\n```\n\n## First Difference\n\n```{r, echo=FALSE}\narrests_ts %>% diff %>% ggtsdisplay()\n```\n\nThe series looks to be stationary at this level, though we should try a seasonal differencing. The seasonal period `s` is clearly 12. There are spikes at 1 and 4 on the ACF plot and spikes at 1, 2, and 4 on the PACF plot. Seasonal spikes occur at 1, 2, and 3 on the ACF plot, and 1 on the PACF plot.\n\n## Seasonal Difference\n\n```{r, echo=FALSE}\narrests_ts %>% diff(12) %>% ggtsdisplay()\n```\n\nThis looks less stationary than a simple first differencing, we will try `D` = 0 and 1.\n\nWe will try the following parameters:\n\n-   p: 1, 2, 4\n-   d: 0, 1\n-   q: 1, 4\n-   P: 1\n-   D: 0, 1\n-   Q: 1, 2, 3\n\n## Build Model\n\n```{r, echo=FALSE}\n# p <- 1\n# d <- 1\n# q <- 1\n# P <- 1\n# D <- 0\n# Q <- 1\ni <- 1\n\ntemp <- data.frame()\nls <- matrix(rep(NA,9*22), nrow=22)\n\nfor(p in c(1,2,3)){\n  for(q in c(1,4)){\n    for(d in c(1)){\n      for(P in c(1)){\n        for(Q in c(1,2,3)){\n          for(D in c(0,1)){\n            if(p + d + q + P + D + Q<= 9){\n              model <- Arima(arrests_ts, order = c(p, d, q), seasonal = c(P, D, Q))\n              ls[i,] <- c(p, d, q, P, D, Q, model$aic, model$bic, model$aicc)\n              i <- i + 1\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\ntemp <- as.data.frame(ls)\nnames(temp) <- c(\"p\",\"d\",\"q\",\"P\", \"D\", \"Q\", \"AIC\",\"BIC\",\"AICc\")\n```\n\n## Model Selection and Diagnostics\n\n### Minimum AIC\n\n```{r, echo=FALSE}\nkable(temp[which.min(temp$AIC),])\n```\n\n### Minimum BIC\n\n```{r, echo = FALSE}\nkable(temp[which.min(temp$BIC),])\n```\n\n### Minimum AICc\n\n```{r, echo = FALSE}\nkable(temp[which.min(temp$AICc),])\n```\n\nIt is clear that the best model is one with parameters $p=1, d=1, q=1, P=1, D=1, Q=1$. We now check the model diagnostics.\n\n```{r, echo = FALSE}\nset.seed(621)\nmodel_output <- capture.output(sarima(arrests_ts, 1, 1, 1, 1, 1, 1, 12))\n```\n\nThe Ljung-Box statistic p-values suggest that there is no correlation between residuals, meaning we have a good model. We will proceed with the model SARIMA(1, 1, 1)(1, 1, 1)12.\n\n### Auto-Arima\n\n```{r, echo = FALSE}\nauto_model <- auto.arima(arrests_ts)\nauto_model\n```\n\nThe information criteria are all better that the previously used model of SARIMA(1, 1, 1)(1, 1, 1)12. This model is absolutely worth considering moving forward.\n\n### Fitted vs. Actual\n\n```{r, echo=FALSE}\nmodel_fit <- Arima(arrests_ts, order = c(1, 1, 1), seasonal = c(1, 1, 1))\nplot(arrests_ts, col = \"blue\")\nlines(fitted(model_fit), col = \"green\")\nlines(fitted(auto_model), col = \"red\")\nlegend(x = \"topright\", legend = c(\"arrests_ts\", \"fit1\", \"fit2\"), fill = 4:1)\n```\n\nBoth fitted models look similar to the actual time series. The two fitted models look incredibly similar, so we will just go with the one we fit by hand.\n\n## Seasonal Cross Validation\n\n1 step ahead and 12 steps ahead\n\n## Forecasting\n\n```{r, echo=FALSE}\nautoplot(arrests_ts) +\n  autolayer(meanf(arrests_ts, h = 36),\n            series = \"Mean\", PI = FALSE) +\n  autolayer(naive(arrests_ts, h = 36),\n            series = \"Naïve\", PI = FALSE) +\n  autolayer(snaive(arrests_ts, h = 36),\n            series = \"SNaïve\", PI = FALSE) +\n  autolayer(rwf(arrests_ts, h = 36, drift = TRUE),\n              series = \"Drift\", PI = FALSE) +\n  autolayer(forecast(model_fit, 36),\n            series = \"Fit\", PI = FALSE) +\n  guides(color = guide_legend(title = \"Forecast\"))\n```\n\nBoth models appear to be better than SNaïve as they do a better job of capturing the trend.\n\nSNaïve model error measurements:\n\n```{r, echo = FALSE}\naccuracy(snaive(arrests_ts, h = 36))\n```\n\nFitted model error measurements:\n\n```{r, echo = FALSE}\nsummary(model_fit)\nsummary(auto_model)\n```\n\nThe model error measurements the model are all much lower than the SNaïve benchmark method.\n\n```{r, echo = FALSE}\nmodel_fit %>% forecast %>% autoplot()\n```\n\n# Assault\n\nWe are fitting a SARIMA model as we saw a clear seasonal component in the previous section. We need to determine the following parameters:\n\n-   p: The order of AR terms.\n-   d: The degree of differencing needed to make the data stationary.\n-   q: The order of MA terms.\n-   P: The seasonal order of AR terms.\n-   D: The seasonal degree of differencing.\n-   Q: The seasonal order of MA terms.\n-   s: The seasonal period.\n\n## ACF and PACF\n\n```{r}\nggtsdisplay(assault_ts)\n```\n\n## First Difference\n\n```{r, echo=FALSE}\nassault_ts %>% diff %>% ggtsdisplay()\n```\n\nThe series looks to be stationary at this level, though we should try a seasonal differencing. The seasonal period `s` is clearly 12. There are spikes at 1 and 2 on the ACF plot and spikes at 1 and 2 on the PACF plot. Seasonal spikes occur at 1, 2, and 3 on the ACF plot, and 1 on the PACF plot.\n\n## Seasonal Difference\n\n```{r, echo=FALSE}\nassault_ts %>% diff(12) %>% ggtsdisplay()\n```\n\nThis looks less stationary than a simple first differencing, we will try `D` = 0 and 1.\n\nWe will try the following parameters:\n\n-   p: 1, 2\n-   d: 1\n-   q: 1, 2\n-   P: 1\n-   D: 0, 1\n-   Q: 1, 2, 3\n\n## Build Model\n\n```{r, echo=FALSE}\ni <- 1\n\ntemp <- data.frame()\nls <- matrix(rep(NA,9*12), nrow=12)\n\nfor(p in c(1,2)){\n  for(q in c(1,2)){\n    for(d in c(1)){\n      for(P in c(1)){\n        for(Q in c(1,2,3)){\n          for(D in c(0,1)){\n            if(p + d + q + P + D + Q<= 7){\n              model <- Arima(assault_ts, order = c(p, d, q), seasonal = c(P, D, Q))\n              ls[i,] <- c(p, d, q, P, D, Q, model$aic, model$bic, model$aicc)\n              i <- i + 1\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\ntemp <- as.data.frame(ls)\nnames(temp) <- c(\"p\",\"d\",\"q\",\"P\", \"D\", \"Q\", \"AIC\",\"BIC\",\"AICc\")\n```\n\n## Model Selection and Diagnostics\n\n### Minimum AIC\n\n```{r, echo=FALSE}\nkable(temp[which.min(temp$AIC),])\n```\n\n### Minimum BIC\n\n```{r, echo = FALSE}\nkable(temp[which.min(temp$BIC),])\n```\n\n### Minimum AICc\n\n```{r, echo = FALSE}\nkable(temp[which.min(temp$AICc),])\n```\n\nIt is clear that the best model is one with parameters $p=1, d=1, q=1, P=1, D=1, Q=1$. We now check the model diagnostics.\n\n```{r  echo = FALSE}\nset.seed(621)\nmodel_output <- capture.output(sarima(assault_ts, 1, 1, 1, 1, 1, 1, 12))\n```\n\nThe Ljung-Box statistic p-values suggest that there is no correlation between residuals at some lag values, meaning we have a good enough model. We will proceed with the model SARIMA(1, 1, 1)(1, 1, 1)12.\n\n### Auto-Arima\n\n```{r, echo = FALSE}\nauto_model <- auto.arima(assault_ts)\nauto_model\n```\n\nThe information criteria are all worse than the previously used model of SARIMA(1, 1, 1)(1, 1, 1)12. This model is not worth considering moving forward.\n\n### Fitted vs. Actual\n\n```{r, echo=FALSE}\nmodel_fit <- Arima(assault_ts, order = c(1, 1, 1), seasonal = c(1, 1, 1))\nplot(assault_ts, col = \"blue\")\nlines(fitted(model_fit), col = \"green\")\nlegend(x = \"topright\", legend = c(\"assault_ts\", \"fit1\"), fill = 4:1)\n```\n\nThe fitted model looks similar to the actual time series.\n\n## Seasonal Cross Validation\n\n1 step ahead and 12 steps ahead\n\n## Forecasting\n\n```{r, echo=FALSE}\nautoplot(assault_ts) +\n  autolayer(meanf(assault_ts, h = 36),\n            series = \"Mean\", PI = FALSE) +\n  autolayer(naive(assault_ts, h = 36),\n            series = \"Naïve\", PI = FALSE) +\n  autolayer(snaive(assault_ts, h = 36),\n            series = \"SNaïve\", PI = FALSE) +\n  autolayer(rwf(assault_ts, h = 36, drift = TRUE),\n              series = \"Drift\", PI = FALSE) +\n  autolayer(forecast(model_fit, 36),\n            series = \"Fit\", PI = FALSE) +\n  guides(color = guide_legend(title = \"Forecast\"))\n```\n\nThis model appears to be better than SNaïve as it does a better job of capturing the trend.\n\nSNaïve model error measurements:\n\n```{r, echo = FALSE}\naccuracy(snaive(assault_ts, h = 36))\n```\n\nFitted model error measurements:\n\n```{r, echo = FALSE}\nsummary(model_fit)\nsummary(auto_model)\n```\n\nThe model error measurements the model are all much lower than the SNaïve benchmark method.\n\n```{r, echo = FALSE}\nmodel_fit %>% forecast %>% autoplot()\n```\n\n# Controlled Substance Possession\n\nWe are fitting a SARIMA model as we saw a clear seasonal component in the previous section. We need to determine the following parameters:\n\n-   p: The order of AR terms.\n-   d: The degree of differencing needed to make the data stationary.\n-   q: The order of MA terms.\n-   P: The seasonal order of AR terms.\n-   D: The seasonal degree of differencing.\n-   Q: The seasonal order of MA terms.\n-   s: The seasonal period.\n\n## ACF and PACF\n\n```{r}\nggtsdisplay(controlled_pos_ts)\n```\n\n## First Difference\n\n```{r, echo=FALSE}\ncontrolled_pos_ts %>% diff %>% ggtsdisplay()\n```\n\nThe series looks to be stationary at this level, though we should try a seasonal differencing. The seasonal period `s` is clearly 12. There are spikes at 1, 3, 4 on the ACF plot and spikes at 1, 2, and 4 on the PACF plot. Seasonal spikes occur at 1, 2, and 3 on the ACF plot, and 1 on the PACF plot.\n\n## Seasonal Difference\n\n```{r, echo=FALSE}\ncontrolled_pos_ts %>% diff(12) %>% ggtsdisplay()\n```\n\nThis looks less stationary than a simple first differencing, we will try `D` = 0 and 1.\n\nWe will try the following parameters:\n\n-   p: 1, 2, 4\n-   d: 1\n-   q: 1, 3, 4\n-   P: 1\n-   D: 0, 1\n-   Q: 1, 2, 3\n\n## Build Model\n\n```{r, echo=FALSE}\ni <- 1\n\ntemp <- data.frame()\nls <- matrix(rep(NA,9*23), nrow=23)\n\nfor(p in c(1,2)){\n  for(q in c(1,2)){\n    for(d in c(1)){\n      for(P in c(1)){\n        for(Q in c(1,2,3)){\n          for(D in c(0,1)){\n            if(p + d + q + P + D + Q <= 9){\n              model <- Arima(controlled_pos_ts, order = c(p, d, q), seasonal = c(P, D, Q))\n              ls[i,] <- c(p, d, q, P, D, Q, model$aic, model$bic, model$aicc)\n              i <- i + 1\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\ntemp <- as.data.frame(ls)\nnames(temp) <- c(\"p\",\"d\",\"q\",\"P\", \"D\", \"Q\", \"AIC\",\"BIC\",\"AICc\")\n```\n\n## Model Selection and Diagnostics\n\n### Minimum AIC\n\n```{r, echo=FALSE}\nkable(temp[which.min(temp$AIC),])\n```\n\n### Minimum BIC\n\n```{r, echo = FALSE}\nkable(temp[which.min(temp$BIC),])\n```\n\n### Minimum AICc\n\n```{r, echo = FALSE}\nkable(temp[which.min(temp$AICc),])\n```\n\nIt is clear that the best model is one with parameters $p=1, d=1, q=1, P=1, D=1, Q=1$. We now check the model diagnostics.\n\n```{r  echo = FALSE}\nset.seed(621)\nmodel_output <- capture.output(sarima(controlled_pos_ts, 1, 1, 1, 1, 1, 1, 12))\n```\n\nThe Ljung-Box statistic p-values suggest that there is no correlation between residuals at some lag values, meaning we have a good enough model. We will proceed with the model SARIMA(1, 1, 1)(1, 1, 1)12.\n\n### Auto-Arima\n\n```{r, echo = FALSE}\nauto_model <- auto.arima(controlled_pos_ts)\nauto_model\n```\n\nThe information criteria are all worse than the previously used model of SARIMA(1, 1, 1)(1, 1, 1)12. This model is not worth considering moving forward.\n\n### Fitted vs. Actual\n\n```{r, echo=FALSE}\nmodel_fit <- Arima(controlled_pos_ts, order = c(1, 1, 1), seasonal = c(1, 1, 1))\nplot(controlled_pos_ts, col = \"blue\")\nlines(fitted(model_fit), col = \"green\")\nlegend(x = \"topright\", legend = c(\"controlled_pos_ts\", \"fit1\"), fill = 4:1)\n```\n\nThe fitted model looks similar to the actual time series.\n\n## Seasonal Cross Validation\n\n1 step ahead and 12 steps ahead\n\n## Forecasting\n\n```{r, echo=FALSE}\nautoplot(controlled_pos_ts) +\n  autolayer(meanf(controlled_pos_ts, h = 36),\n            series = \"Mean\", PI = FALSE) +\n  autolayer(naive(controlled_pos_ts, h = 36),\n            series = \"Naïve\", PI = FALSE) +\n  autolayer(snaive(controlled_pos_ts, h = 36),\n            series = \"SNaïve\", PI = FALSE) +\n  autolayer(rwf(controlled_pos_ts, h = 36, drift = TRUE),\n              series = \"Drift\", PI = FALSE) +\n  autolayer(forecast(model_fit, 36),\n            series = \"Fit\", PI = FALSE) +\n  guides(color = guide_legend(title = \"Forecast\"))\n```\n\nThis model appears to be better than SNaïve as it does a better job of capturing the trend.\n\nSNaïve model error measurements:\n\n```{r, echo = FALSE}\naccuracy(snaive(controlled_pos_ts, h = 36))\n```\n\nFitted model error measurements:\n\n```{r, echo = FALSE}\nsummary(model_fit)\nsummary(auto_model)\n```\n\nThe model error measurements the model are all much lower than the SNaïve benchmark method.\n\n```{r, echo = FALSE}\nmodel_fit %>% forecast %>% autoplot()\n```\n\n# Marijuana Possession\n\nWe are fitting a SARIMA model as we saw a clear seasonal component in the previous section. We need to determine the following parameters:\n\n-   p: The order of AR terms.\n-   d: The degree of differencing needed to make the data stationary.\n-   q: The order of MA terms.\n-   P: The seasonal order of AR terms.\n-   D: The seasonal degree of differencing.\n-   Q: The seasonal order of MA terms.\n-   s: The seasonal period.\n\n## ACF and PACF\n\n```{r}\nggtsdisplay(marijuana_pos_ts)\n```\n\n## First Difference\n\n```{r, echo=FALSE}\nmarijuana_pos_ts %>% diff %>% ggtsdisplay()\n```\n\nThere still looks to be a trend at this level, we should try to difference one more time. We should also try a seasonal differencing at a seasonal period of 12. \n\n## Second Difference\n```{r}\nmarijuana_pos_ts %>% diff() %>% diff() %>% ggtsdisplay()\n```\n\nThis looks more stationary, we should determine parameters to try from here. \n\nThe seasonal period `s` is clearly 12. There are spikes at 1 and 4 on the ACF plot and spikes at 1, 2, and 4 on the PACF plot. Seasonal spikes occur at 1, 2, and 3 on the ACF plot, and 1 on the PACF plot.\n\n## Seasonal Difference\n\n```{r, echo=FALSE}\nmarijuana_pos_ts %>% diff(12) %>% ggtsdisplay()\n```\n\nThis looks less stationary than a simple first differencing, we will try `D` = 0 and 1.\n\nWe will try the following parameters:\n\n-   p: 1, 2, 4\n-   d: 1, 2\n-   q: 1, 4\n-   P: 1\n-   D: 0, 1\n-   Q: 1, 2, 3\n\n## Build Model\n\n```{r, echo=FALSE}\ni <- 1\n\ntemp <- data.frame()\nls <- matrix(rep(NA,9*32), nrow=32)\n\nfor(p in c(1,2,4)){\n  for(q in c(1,4)){\n    for(d in c(1,2)){\n      for(P in c(1)){\n        for(Q in c(1,2,3)){\n          for(D in c(0,1)){\n            if(p + d + q + P + D + Q<= 9){\n              model <- Arima(marijuana_pos_ts, order = c(p, d, q), seasonal = c(P, D, Q))\n              ls[i,] <- c(p, d, q, P, D, Q, model$aic, model$bic, model$aicc)\n              i <- i + 1\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\ntemp <- as.data.frame(ls)\nnames(temp) <- c(\"p\",\"d\",\"q\",\"P\", \"D\", \"Q\", \"AIC\",\"BIC\",\"AICc\")\n```\n\n## Model Selection and Diagnostics\n\n### Minimum AIC\n\n```{r, echo=FALSE}\nkable(temp[which.min(temp$AIC),])\n```\n\n### Minimum BIC\n\n```{r, echo = FALSE}\nkable(temp[which.min(temp$BIC),])\n```\n\n### Minimum AICc\n\n```{r, echo = FALSE}\nkable(temp[which.min(temp$AICc),])\n```\n\nIt is clear that the best model is one with parameters $p=1, d=1, q=1, P=1, D=1, Q=1$. We now check the model diagnostics.\n\n```{r  echo = FALSE}\nset.seed(621)\nmodel_output <- capture.output(sarima(marijuana_pos_ts, 1, 1, 1, 1, 1, 1, 12))\n```\n\nThe Ljung-Box statistic p-values suggest that there is no correlation between residuals at some lag values, meaning we have a good enough model. We will proceed with the model SARIMA(1, 1, 1)(1, 1, 1)12.\n\n### Auto-Arima\n\n```{r, echo = FALSE}\nauto_model <- auto.arima(marijuana_pos_ts)\nauto_model\n```\n\nThe information criteria are all slightly better than the previously used model of SARIMA(1, 1, 1)(1, 1, 1)12, but not so much better that this model would be worth considering moving forward.\n\n### Fitted vs. Actual\n\n```{r, echo=FALSE}\nmodel_fit <- Arima(marijuana_pos_ts, order = c(1, 1, 1), seasonal = c(1, 1, 1))\nplot(marijuana_pos_ts, col = \"blue\")\nlines(fitted(model_fit), col = \"green\")\nlegend(x = \"topright\", legend = c(\"marijuana_pos_ts\", \"fit1\"), fill = 4:1)\n```\n\nThe fitted model looks similar to the actual time series.\n\n## Seasonal Cross Validation\n\n1 step ahead and 12 steps ahead\n\n## Forecasting\n\n```{r, echo=FALSE}\nautoplot(marijuana_pos_ts) +\n  autolayer(meanf(marijuana_pos_ts, h = 36),\n            series = \"Mean\", PI = FALSE) +\n  autolayer(naive(marijuana_pos_ts, h = 36),\n            series = \"Naïve\", PI = FALSE) +\n  autolayer(snaive(marijuana_pos_ts, h = 36),\n            series = \"SNaïve\", PI = FALSE) +\n  autolayer(rwf(marijuana_pos_ts, h = 36, drift = TRUE),\n              series = \"Drift\", PI = FALSE) +\n  autolayer(forecast(model_fit, 36),\n            series = \"Fit\", PI = FALSE) +\n  guides(color = guide_legend(title = \"Forecast\"))\n```\n\nThis model appears to be better than SNaïve as it does a better job of capturing the trend.\n\nSNaïve model error measurements:\n\n```{r, echo = FALSE}\naccuracy(snaive(marijuana_pos_ts, h = 36))\n```\n\nFitted model error measurements:\n\n```{r, echo = FALSE}\nsummary(model_fit)\nsummary(auto_model)\n```\n\nThe model error measurements the model are all much lower than the SNaïve benchmark method.\n\n```{r, echo = FALSE}\nmodel_fit %>% forecast %>% autoplot()\n```\n\nIt doesn't really make sense to forecast here as we can be sure that there will be no more arrests for marijuana possession, but it is good to know that we have fitted a good model. We can predict what would have happened to the level of arrests if the policy changes that were instituded over the years never happened. \n\n# Motor Vehicle Theft\n\nWe are fitting an ARIMA model as we did not see a clear seasonal component in the previous section. We need to determine the following parameters:\n\n-   p: The order of AR terms.\n-   d: The degree of differencing needed to make the data stationary.\n-   q: The order of MA terms.\n\n## ACF and PACF\n\n```{r}\nggtsdisplay(motor_theft_ts)\n```\n\n## First Difference\n\n```{r, echo=FALSE}\nmotor_theft_ts %>% diff %>% ggtsdisplay()\n```\n\nThis looks to be slightly more stationary than the original series, we can proceed with the model build process. There are spikes at 1 and 3 on the ACF plot and spikes at 1, 2 on the PACF plot. \n\nWe will try the following parameters:\n\n-   p: 1, 2\n-   d: 0, 1\n-   q: 1, 3\n\n## Build Model\n\n```{r, echo=FALSE}\ni <- 1\n\ntemp <- data.frame()\nls <- matrix(rep(NA,6*8), nrow=8)\n\nfor(p in c(1,2)){\n  for(q in c(1,3)){\n    for(d in c(0,1)){\n      if(p + d + q <= 8){\n        model <- Arima(motor_theft_ts, order = c(p, d, q))\n        ls[i,] <- c(p, d, q, model$aic, model$bic, model$aicc)\n        i <- i + 1\n      }\n    }\n  }\n}\n\ntemp <- as.data.frame(ls)\nnames(temp) <- c(\"p\",\"d\",\"q\", \"AIC\",\"BIC\",\"AICc\")\n```\n\n## Model Selection and Diagnostics\n\n### Minimum AIC\n\n```{r, echo=FALSE}\nkable(temp[which.min(temp$AIC),])\n```\n\n### Minimum BIC\n\n```{r, echo = FALSE}\nkable(temp[which.min(temp$BIC),])\n```\n\n### Minimum AICc\n\n```{r, echo = FALSE}\nkable(temp[which.min(temp$AICc),])\n```\n\nIt is clear that the best model is one with parameters $p=2, d=1, q=3$. We now check the model diagnostics.\n\n```{r  echo = FALSE}\nset.seed(621)\nmodel_output <- capture.output(sarima(motor_theft_ts, 2, 1, 3))\n```\n\nThe Ljung-Box statistic p-values suggest that there may be correlation between residuals at some lag values, meaning we might not have a good enough model. We will still proceed with the model ARIMA(2, 1, 3).\n\n### Auto-Arima\n\n```{r, echo = FALSE}\nauto_model <- auto.arima(motor_theft_ts)\nauto_model\n```\n\nThe information criteria are all slightly better than the previously used model of ARIMA(2, 1, 3), and it considers the seasonal component, so this model would be worth considering moving forward.\n\n### Fitted vs. Actual\n\n```{r, echo=FALSE}\nmodel_fit <- Arima(motor_theft_ts, order = c(2, 1, 3))\nplot(motor_theft_ts, col = \"blue\")\nlines(fitted(model_fit), col = \"green\")\nlines(fitted(auto_model), col = \"red\")\nlegend(x = \"topright\", legend = c(\"motor_theft_ts\", \"fit1\", \"auto_fit\"), fill = 4:1)\n```\n\nThe fitted model and auto mdoel look similar to the actual time series.\n\n## Seasonal Cross Validation\n\n1 step ahead and 12 steps ahead\n\n## Forecasting\n\n```{r, echo=FALSE}\nautoplot(motor_theft_ts) +\n  autolayer(meanf(motor_theft_ts, h = 36),\n            series = \"Mean\", PI = FALSE) +\n  autolayer(naive(motor_theft_ts, h = 36),\n            series = \"Naïve\", PI = FALSE) +\n  autolayer(snaive(motor_theft_ts, h = 36),\n            series = \"SNaïve\", PI = FALSE) +\n  autolayer(rwf(motor_theft_ts, h = 36, drift = TRUE),\n              series = \"Drift\", PI = FALSE) +\n  autolayer(forecast(model_fit, 36),\n            series = \"Fit\", PI = FALSE) +\n  autolayer(forecast(auto_model, 36),\n            series = \"Auto Fit\", PI = FALSE) +\n  guides(color = guide_legend(title = \"Forecast\"))\n```\n\nBoth models appear to be better than SNaïve as they does a better job of capturing the trend. It is hard to tell which is better between the fit and the auto fit. \n\nSNaïve model error measurements:\n\n```{r, echo = FALSE}\naccuracy(snaive(motor_theft_ts, h = 36))\n```\n\nFitted model error measurements:\n\n```{r, echo = FALSE}\nsummary(model_fit)\nsummary(auto_model)\n```\n\nThe model error measurements the model are all much lower than the SNaïve benchmark method. The seasonal, auto fitted model slightly outperforms the non-seasonal ARIMA model, so we will go with that model. \n\n```{r, echo = FALSE}\nauto_model %>% forecast %>% autoplot()\n```\n\n# Murder\n\nWe are fitting an ARIMA model as we did not see a clear seasonal component in the previous section. We need to determine the following parameters:\n\n-   p: The order of AR terms.\n-   d: The degree of differencing needed to make the data stationary.\n-   q: The order of MA terms.\n\n## ACF and PACF\n\n```{r}\nggtsdisplay(murder_ts)\n```\n\n## First Difference\n\n```{r, echo=FALSE}\nmurder_ts %>% diff %>% ggtsdisplay()\n```\n\nThis looks to be much more stationary than the original series, we can proceed with the model build process. There are spikes at 1 on the ACF plot and spikes at 1 and 2 on the PACF plot. \n\nWe will try the following parameters:\n\n-   p: 1\n-   d: 0, 1\n-   q: 1, 2\n\n## Build Model\n\n```{r, echo=FALSE}\ni <- 1\n\ntemp <- data.frame()\nls <- matrix(rep(NA,6*4), nrow=4)\n\nfor(p in c(1)){\n  for(q in c(1,2)){\n    for(d in c(0,1)){\n      if(p + d + q <= 8){\n        model <- Arima(murder_ts, order = c(p, d, q))\n        ls[i,] <- c(p, d, q, model$aic, model$bic, model$aicc)\n        i <- i + 1\n      }\n    }\n  }\n}\n\ntemp <- as.data.frame(ls)\nnames(temp) <- c(\"p\",\"d\",\"q\", \"AIC\",\"BIC\",\"AICc\")\n```\n\n## Model Selection and Diagnostics\n\n### Minimum AIC\n\n```{r, echo=FALSE}\nkable(temp[which.min(temp$AIC),])\n```\n\n### Minimum BIC\n\n```{r, echo = FALSE}\nkable(temp[which.min(temp$BIC),])\n```\n\n### Minimum AICc\n\n```{r, echo = FALSE}\nkable(temp[which.min(temp$AICc),])\n```\n\nIt is clear that the best model is one with parameters $p=1, d=1, q=2$. We now check the model diagnostics.\n\n```{r  echo = FALSE}\nset.seed(621)\nmodel_output <- capture.output(sarima(murder_ts, 1, 1, 2))\n```\n\nThe Ljung-Box statistic p-values suggest that there may be correlation between residuals at some lag values, meaning we might not have a good enough model. We will still proceed with the model ARIMA(1, 1, 2).\n\n### Auto-Arima\n\n```{r, echo = FALSE}\nauto_model <- auto.arima(murder_ts)\nauto_model\n```\n\nThe information criteria are all slightly better than the previously used model of ARIMA(1, 1, 2), but not so much better that this model would be worth considering moving forward.\n\n### Fitted vs. Actual\n\n```{r, echo=FALSE}\nmodel_fit <- Arima(murder_ts, order = c(1, 1, 2))\nplot(murder_ts, col = \"blue\")\nlines(fitted(model_fit), col = \"green\")\nlegend(x = \"topleft\", legend = c(\"murder_ts\", \"fit1\"), fill = 4:1)\n```\n\nThe fitted model and auto mdoel look similar to the actual time series.\n\n## Seasonal Cross Validation\n\n1 step ahead and 12 steps ahead\n\n## Forecasting\n\n```{r, echo=FALSE}\nautoplot(murder_ts) +\n  autolayer(meanf(murder_ts, h = 36),\n            series = \"Mean\", PI = FALSE) +\n  autolayer(naive(murder_ts, h = 36),\n            series = \"Naïve\", PI = FALSE) +\n  autolayer(snaive(murder_ts, h = 36),\n            series = \"SNaïve\", PI = FALSE) +\n  autolayer(rwf(murder_ts, h = 36, drift = TRUE),\n              series = \"Drift\", PI = FALSE) +\n  autolayer(forecast(model_fit, 36),\n            series = \"Fit\", PI = FALSE) +\n  guides(color = guide_legend(title = \"Forecast\"))\n```\n\nThe fitted model is better than SNaïve as they does a better job of capturing the trend.\n\nSNaïve model error measurements:\n\n```{r, echo = FALSE}\naccuracy(snaive(murder_ts, h = 36))\n```\n\nFitted model error measurements:\n\n```{r, echo = FALSE}\nsummary(model_fit)\n```\n\nThe model error measurements the model are all much lower than the SNaïve benchmark method.\n\n```{r, echo = FALSE}\nmodel_fit %>% forecast %>% autoplot()\n```\n\n# Robbery\n\nWe are fitting a SARIMA model as we saw a clear seasonal component in the previous section. We need to determine the following parameters:\n\n-   p: The order of AR terms.\n-   d: The degree of differencing needed to make the data stationary.\n-   q: The order of MA terms.\n-   P: The seasonal order of AR terms.\n-   D: The seasonal degree of differencing.\n-   Q: The seasonal order of MA terms.\n-   s: The seasonal period.\n\n## ACF and PACF\n\n```{r}\nggtsdisplay(robbery_ts)\n```\n\n## First Difference\n\n```{r, echo=FALSE}\nrobbery_ts %>% diff %>% ggtsdisplay()\n```\n\nThe series looks to be stationary here. We should also try a seasonal differencing at a seasonal period of 12. \n\nThe seasonal period `s` is clearly 12. There are spikes at 1 and 4 on the ACF plot and spikes at 1, 2, and 4 on the PACF plot. Seasonal spikes occur at 1, 2, and 3 on the ACF plot, and 1 on the PACF plot.\n\n## Seasonal Difference\n\n```{r, echo=FALSE}\nrobbery_ts %>% diff(12) %>% ggtsdisplay()\n```\n\nThis looks less stationary than a simple first differencing, we will try `D` = 0 and 1.\n\nWe will try the following parameters:\n\n-   p: 1, 2, 4\n-   d: 1\n-   q: 1, 4\n-   P: 1\n-   D: 0, 1\n-   Q: 1, 2, 3\n\n## Build Model\n\n```{r, echo=FALSE}\ni <- 1\n\ntemp <- data.frame()\nls <- matrix(rep(NA,9*19), nrow=19)\n\nfor(p in c(1,2,4)){\n  for(q in c(1,4)){\n    for(d in c(1)){\n      for(P in c(1)){\n        for(Q in c(1,2,3)){\n          for(D in c(0,1)){\n            if(p + d + q + P + D + Q<= 9){\n              tryCatch({\n                model <- Arima(robbery_ts, order = c(p, d, q), seasonal = c(P, D, Q))\n                ls[i,] <- c(p, d, q, P, D, Q, model$aic, model$bic, model$aicc)\n              }, error = function(err) {\n                cat(\"error: \", p, d, q, P, D, Q, \"\\n\")\n              }, finally = {\n                i <- i + 1\n              })\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\ntemp <- as.data.frame(ls)\nnames(temp) <- c(\"p\",\"d\",\"q\",\"P\", \"D\", \"Q\", \"AIC\",\"BIC\",\"AICc\")\n```\n\n## Model Selection and Diagnostics\n\n### Minimum AIC\n\n```{r, echo=FALSE}\nkable(temp[which.min(temp$AIC),])\n```\n\n### Minimum BIC\n\n```{r, echo = FALSE}\nkable(temp[which.min(temp$BIC),])\n```\n\n### Minimum AICc\n\n```{r, echo = FALSE}\nkable(temp[which.min(temp$AICc),])\n```\n\nIt is clear that the best model is one with parameters $p=1, d=1, q=1, P=1, D=1, Q=2$. We now check the model diagnostics.\n\n```{r, echo = FALSE}\nset.seed(621)\nmodel_output <- capture.output(sarima(robbery_ts, 1, 1, 1, 1, 1, 2, 12))\n```\n\nThe Ljung-Box statistic p-values suggest that there is no correlation between residuals, meaning we have a good enough model. We will proceed with the model SARIMA(1, 1, 1)(1, 1, 2)12.\n\n### Auto-Arima\n\n```{r, echo = FALSE}\nauto_model <- auto.arima(robbery_ts)\nauto_model\n```\n\nThe information criteria are all worse than the previously used model of SARIMA(1, 1, 1)(1, 1, 2)12, this model is not worth considering moving forward.\n\n### Fitted vs. Actual\n\n```{r, echo=FALSE}\nmodel_fit <- Arima(robbery_ts, order = c(1, 1, 1), seasonal = c(1, 1, 2))\nplot(robbery_ts, col = \"blue\")\nlines(fitted(model_fit), col = \"green\")\nlegend(x = \"topright\", legend = c(\"robbery_ts\", \"fit1\"), fill = 4:1)\n```\n\nThe fitted model looks similar to the actual time series.\n\n## Seasonal Cross Validation\n\n1 step ahead and 12 steps ahead\n\n## Forecasting\n\n```{r, echo=FALSE}\nautoplot(robbery_ts) +\n  autolayer(meanf(robbery_ts, h = 36),\n            series = \"Mean\", PI = FALSE) +\n  autolayer(naive(robbery_ts, h = 36),\n            series = \"Naïve\", PI = FALSE) +\n  autolayer(snaive(robbery_ts, h = 36),\n            series = \"SNaïve\", PI = FALSE) +\n  autolayer(rwf(robbery_ts, h = 36, drift = TRUE),\n              series = \"Drift\", PI = FALSE) +\n  autolayer(forecast(model_fit, 36),\n            series = \"Fit\", PI = FALSE) +\n  guides(color = guide_legend(title = \"Forecast\"))\n```\n\nThis model appears to be better than SNaïve as it does a better job of capturing the trend.\n\nSNaïve model error measurements:\n\n```{r, echo = FALSE}\naccuracy(snaive(robbery_ts, h = 36))\n```\n\nFitted model error measurements:\n\n```{r, echo = FALSE}\nsummary(model_fit)\n```\n\nThe model error measurements the model are all much lower than the SNaïve benchmark method.\n\n```{r, echo = FALSE}\nmodel_fit %>% forecast %>% autoplot()\n```\n\n\n\n:::\n","srcMarkdownNoYaml":"\n\n```{r include = FALSE}\nknitr::opts_chunk$set(echo = FALSE)\n```\n\n# Fitting NYC Arrests Series by Crime\n\n```{r setup, include = FALSE}\nlibrary(reticulate)\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(ggplot2)\nlibrary(forecast)\nlibrary(TSstudio)\nlibrary(tseries)\nlibrary(gridExtra)\nlibrary(kableExtra)\nlibrary(astsa)\nload(\"arrests_ts.Rdata\")\n```\n\n::: panel-tabset\n# Total\n\nWe are fitting a SARIMA model as we saw a clear seasonal component in the previous section. We need to determine the following parameters:\n\n-   p: The order of AR terms.\n-   d: The degree of differencing needed to make the data stationary.\n-   q: The order of MA terms.\n-   P: The seasonal order of AR terms.\n-   D: The seasonal degree of differencing.\n-   Q: The seasonal order of MA terms.\n-   s: The seasonal period.\n\n## ACF and PACF\n\n```{r}\nggtsdisplay(arrests_ts)\n```\n\n## First Difference\n\n```{r, echo=FALSE}\narrests_ts %>% diff %>% ggtsdisplay()\n```\n\nThe series looks to be stationary at this level, though we should try a seasonal differencing. The seasonal period `s` is clearly 12. There are spikes at 1 and 4 on the ACF plot and spikes at 1, 2, and 4 on the PACF plot. Seasonal spikes occur at 1, 2, and 3 on the ACF plot, and 1 on the PACF plot.\n\n## Seasonal Difference\n\n```{r, echo=FALSE}\narrests_ts %>% diff(12) %>% ggtsdisplay()\n```\n\nThis looks less stationary than a simple first differencing, we will try `D` = 0 and 1.\n\nWe will try the following parameters:\n\n-   p: 1, 2, 4\n-   d: 0, 1\n-   q: 1, 4\n-   P: 1\n-   D: 0, 1\n-   Q: 1, 2, 3\n\n## Build Model\n\n```{r, echo=FALSE}\n# p <- 1\n# d <- 1\n# q <- 1\n# P <- 1\n# D <- 0\n# Q <- 1\ni <- 1\n\ntemp <- data.frame()\nls <- matrix(rep(NA,9*22), nrow=22)\n\nfor(p in c(1,2,3)){\n  for(q in c(1,4)){\n    for(d in c(1)){\n      for(P in c(1)){\n        for(Q in c(1,2,3)){\n          for(D in c(0,1)){\n            if(p + d + q + P + D + Q<= 9){\n              model <- Arima(arrests_ts, order = c(p, d, q), seasonal = c(P, D, Q))\n              ls[i,] <- c(p, d, q, P, D, Q, model$aic, model$bic, model$aicc)\n              i <- i + 1\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\ntemp <- as.data.frame(ls)\nnames(temp) <- c(\"p\",\"d\",\"q\",\"P\", \"D\", \"Q\", \"AIC\",\"BIC\",\"AICc\")\n```\n\n## Model Selection and Diagnostics\n\n### Minimum AIC\n\n```{r, echo=FALSE}\nkable(temp[which.min(temp$AIC),])\n```\n\n### Minimum BIC\n\n```{r, echo = FALSE}\nkable(temp[which.min(temp$BIC),])\n```\n\n### Minimum AICc\n\n```{r, echo = FALSE}\nkable(temp[which.min(temp$AICc),])\n```\n\nIt is clear that the best model is one with parameters $p=1, d=1, q=1, P=1, D=1, Q=1$. We now check the model diagnostics.\n\n```{r, echo = FALSE}\nset.seed(621)\nmodel_output <- capture.output(sarima(arrests_ts, 1, 1, 1, 1, 1, 1, 12))\n```\n\nThe Ljung-Box statistic p-values suggest that there is no correlation between residuals, meaning we have a good model. We will proceed with the model SARIMA(1, 1, 1)(1, 1, 1)12.\n\n### Auto-Arima\n\n```{r, echo = FALSE}\nauto_model <- auto.arima(arrests_ts)\nauto_model\n```\n\nThe information criteria are all better that the previously used model of SARIMA(1, 1, 1)(1, 1, 1)12. This model is absolutely worth considering moving forward.\n\n### Fitted vs. Actual\n\n```{r, echo=FALSE}\nmodel_fit <- Arima(arrests_ts, order = c(1, 1, 1), seasonal = c(1, 1, 1))\nplot(arrests_ts, col = \"blue\")\nlines(fitted(model_fit), col = \"green\")\nlines(fitted(auto_model), col = \"red\")\nlegend(x = \"topright\", legend = c(\"arrests_ts\", \"fit1\", \"fit2\"), fill = 4:1)\n```\n\nBoth fitted models look similar to the actual time series. The two fitted models look incredibly similar, so we will just go with the one we fit by hand.\n\n## Seasonal Cross Validation\n\n1 step ahead and 12 steps ahead\n\n## Forecasting\n\n```{r, echo=FALSE}\nautoplot(arrests_ts) +\n  autolayer(meanf(arrests_ts, h = 36),\n            series = \"Mean\", PI = FALSE) +\n  autolayer(naive(arrests_ts, h = 36),\n            series = \"Naïve\", PI = FALSE) +\n  autolayer(snaive(arrests_ts, h = 36),\n            series = \"SNaïve\", PI = FALSE) +\n  autolayer(rwf(arrests_ts, h = 36, drift = TRUE),\n              series = \"Drift\", PI = FALSE) +\n  autolayer(forecast(model_fit, 36),\n            series = \"Fit\", PI = FALSE) +\n  guides(color = guide_legend(title = \"Forecast\"))\n```\n\nBoth models appear to be better than SNaïve as they do a better job of capturing the trend.\n\nSNaïve model error measurements:\n\n```{r, echo = FALSE}\naccuracy(snaive(arrests_ts, h = 36))\n```\n\nFitted model error measurements:\n\n```{r, echo = FALSE}\nsummary(model_fit)\nsummary(auto_model)\n```\n\nThe model error measurements the model are all much lower than the SNaïve benchmark method.\n\n```{r, echo = FALSE}\nmodel_fit %>% forecast %>% autoplot()\n```\n\n# Assault\n\nWe are fitting a SARIMA model as we saw a clear seasonal component in the previous section. We need to determine the following parameters:\n\n-   p: The order of AR terms.\n-   d: The degree of differencing needed to make the data stationary.\n-   q: The order of MA terms.\n-   P: The seasonal order of AR terms.\n-   D: The seasonal degree of differencing.\n-   Q: The seasonal order of MA terms.\n-   s: The seasonal period.\n\n## ACF and PACF\n\n```{r}\nggtsdisplay(assault_ts)\n```\n\n## First Difference\n\n```{r, echo=FALSE}\nassault_ts %>% diff %>% ggtsdisplay()\n```\n\nThe series looks to be stationary at this level, though we should try a seasonal differencing. The seasonal period `s` is clearly 12. There are spikes at 1 and 2 on the ACF plot and spikes at 1 and 2 on the PACF plot. Seasonal spikes occur at 1, 2, and 3 on the ACF plot, and 1 on the PACF plot.\n\n## Seasonal Difference\n\n```{r, echo=FALSE}\nassault_ts %>% diff(12) %>% ggtsdisplay()\n```\n\nThis looks less stationary than a simple first differencing, we will try `D` = 0 and 1.\n\nWe will try the following parameters:\n\n-   p: 1, 2\n-   d: 1\n-   q: 1, 2\n-   P: 1\n-   D: 0, 1\n-   Q: 1, 2, 3\n\n## Build Model\n\n```{r, echo=FALSE}\ni <- 1\n\ntemp <- data.frame()\nls <- matrix(rep(NA,9*12), nrow=12)\n\nfor(p in c(1,2)){\n  for(q in c(1,2)){\n    for(d in c(1)){\n      for(P in c(1)){\n        for(Q in c(1,2,3)){\n          for(D in c(0,1)){\n            if(p + d + q + P + D + Q<= 7){\n              model <- Arima(assault_ts, order = c(p, d, q), seasonal = c(P, D, Q))\n              ls[i,] <- c(p, d, q, P, D, Q, model$aic, model$bic, model$aicc)\n              i <- i + 1\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\ntemp <- as.data.frame(ls)\nnames(temp) <- c(\"p\",\"d\",\"q\",\"P\", \"D\", \"Q\", \"AIC\",\"BIC\",\"AICc\")\n```\n\n## Model Selection and Diagnostics\n\n### Minimum AIC\n\n```{r, echo=FALSE}\nkable(temp[which.min(temp$AIC),])\n```\n\n### Minimum BIC\n\n```{r, echo = FALSE}\nkable(temp[which.min(temp$BIC),])\n```\n\n### Minimum AICc\n\n```{r, echo = FALSE}\nkable(temp[which.min(temp$AICc),])\n```\n\nIt is clear that the best model is one with parameters $p=1, d=1, q=1, P=1, D=1, Q=1$. We now check the model diagnostics.\n\n```{r  echo = FALSE}\nset.seed(621)\nmodel_output <- capture.output(sarima(assault_ts, 1, 1, 1, 1, 1, 1, 12))\n```\n\nThe Ljung-Box statistic p-values suggest that there is no correlation between residuals at some lag values, meaning we have a good enough model. We will proceed with the model SARIMA(1, 1, 1)(1, 1, 1)12.\n\n### Auto-Arima\n\n```{r, echo = FALSE}\nauto_model <- auto.arima(assault_ts)\nauto_model\n```\n\nThe information criteria are all worse than the previously used model of SARIMA(1, 1, 1)(1, 1, 1)12. This model is not worth considering moving forward.\n\n### Fitted vs. Actual\n\n```{r, echo=FALSE}\nmodel_fit <- Arima(assault_ts, order = c(1, 1, 1), seasonal = c(1, 1, 1))\nplot(assault_ts, col = \"blue\")\nlines(fitted(model_fit), col = \"green\")\nlegend(x = \"topright\", legend = c(\"assault_ts\", \"fit1\"), fill = 4:1)\n```\n\nThe fitted model looks similar to the actual time series.\n\n## Seasonal Cross Validation\n\n1 step ahead and 12 steps ahead\n\n## Forecasting\n\n```{r, echo=FALSE}\nautoplot(assault_ts) +\n  autolayer(meanf(assault_ts, h = 36),\n            series = \"Mean\", PI = FALSE) +\n  autolayer(naive(assault_ts, h = 36),\n            series = \"Naïve\", PI = FALSE) +\n  autolayer(snaive(assault_ts, h = 36),\n            series = \"SNaïve\", PI = FALSE) +\n  autolayer(rwf(assault_ts, h = 36, drift = TRUE),\n              series = \"Drift\", PI = FALSE) +\n  autolayer(forecast(model_fit, 36),\n            series = \"Fit\", PI = FALSE) +\n  guides(color = guide_legend(title = \"Forecast\"))\n```\n\nThis model appears to be better than SNaïve as it does a better job of capturing the trend.\n\nSNaïve model error measurements:\n\n```{r, echo = FALSE}\naccuracy(snaive(assault_ts, h = 36))\n```\n\nFitted model error measurements:\n\n```{r, echo = FALSE}\nsummary(model_fit)\nsummary(auto_model)\n```\n\nThe model error measurements the model are all much lower than the SNaïve benchmark method.\n\n```{r, echo = FALSE}\nmodel_fit %>% forecast %>% autoplot()\n```\n\n# Controlled Substance Possession\n\nWe are fitting a SARIMA model as we saw a clear seasonal component in the previous section. We need to determine the following parameters:\n\n-   p: The order of AR terms.\n-   d: The degree of differencing needed to make the data stationary.\n-   q: The order of MA terms.\n-   P: The seasonal order of AR terms.\n-   D: The seasonal degree of differencing.\n-   Q: The seasonal order of MA terms.\n-   s: The seasonal period.\n\n## ACF and PACF\n\n```{r}\nggtsdisplay(controlled_pos_ts)\n```\n\n## First Difference\n\n```{r, echo=FALSE}\ncontrolled_pos_ts %>% diff %>% ggtsdisplay()\n```\n\nThe series looks to be stationary at this level, though we should try a seasonal differencing. The seasonal period `s` is clearly 12. There are spikes at 1, 3, 4 on the ACF plot and spikes at 1, 2, and 4 on the PACF plot. Seasonal spikes occur at 1, 2, and 3 on the ACF plot, and 1 on the PACF plot.\n\n## Seasonal Difference\n\n```{r, echo=FALSE}\ncontrolled_pos_ts %>% diff(12) %>% ggtsdisplay()\n```\n\nThis looks less stationary than a simple first differencing, we will try `D` = 0 and 1.\n\nWe will try the following parameters:\n\n-   p: 1, 2, 4\n-   d: 1\n-   q: 1, 3, 4\n-   P: 1\n-   D: 0, 1\n-   Q: 1, 2, 3\n\n## Build Model\n\n```{r, echo=FALSE}\ni <- 1\n\ntemp <- data.frame()\nls <- matrix(rep(NA,9*23), nrow=23)\n\nfor(p in c(1,2)){\n  for(q in c(1,2)){\n    for(d in c(1)){\n      for(P in c(1)){\n        for(Q in c(1,2,3)){\n          for(D in c(0,1)){\n            if(p + d + q + P + D + Q <= 9){\n              model <- Arima(controlled_pos_ts, order = c(p, d, q), seasonal = c(P, D, Q))\n              ls[i,] <- c(p, d, q, P, D, Q, model$aic, model$bic, model$aicc)\n              i <- i + 1\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\ntemp <- as.data.frame(ls)\nnames(temp) <- c(\"p\",\"d\",\"q\",\"P\", \"D\", \"Q\", \"AIC\",\"BIC\",\"AICc\")\n```\n\n## Model Selection and Diagnostics\n\n### Minimum AIC\n\n```{r, echo=FALSE}\nkable(temp[which.min(temp$AIC),])\n```\n\n### Minimum BIC\n\n```{r, echo = FALSE}\nkable(temp[which.min(temp$BIC),])\n```\n\n### Minimum AICc\n\n```{r, echo = FALSE}\nkable(temp[which.min(temp$AICc),])\n```\n\nIt is clear that the best model is one with parameters $p=1, d=1, q=1, P=1, D=1, Q=1$. We now check the model diagnostics.\n\n```{r  echo = FALSE}\nset.seed(621)\nmodel_output <- capture.output(sarima(controlled_pos_ts, 1, 1, 1, 1, 1, 1, 12))\n```\n\nThe Ljung-Box statistic p-values suggest that there is no correlation between residuals at some lag values, meaning we have a good enough model. We will proceed with the model SARIMA(1, 1, 1)(1, 1, 1)12.\n\n### Auto-Arima\n\n```{r, echo = FALSE}\nauto_model <- auto.arima(controlled_pos_ts)\nauto_model\n```\n\nThe information criteria are all worse than the previously used model of SARIMA(1, 1, 1)(1, 1, 1)12. This model is not worth considering moving forward.\n\n### Fitted vs. Actual\n\n```{r, echo=FALSE}\nmodel_fit <- Arima(controlled_pos_ts, order = c(1, 1, 1), seasonal = c(1, 1, 1))\nplot(controlled_pos_ts, col = \"blue\")\nlines(fitted(model_fit), col = \"green\")\nlegend(x = \"topright\", legend = c(\"controlled_pos_ts\", \"fit1\"), fill = 4:1)\n```\n\nThe fitted model looks similar to the actual time series.\n\n## Seasonal Cross Validation\n\n1 step ahead and 12 steps ahead\n\n## Forecasting\n\n```{r, echo=FALSE}\nautoplot(controlled_pos_ts) +\n  autolayer(meanf(controlled_pos_ts, h = 36),\n            series = \"Mean\", PI = FALSE) +\n  autolayer(naive(controlled_pos_ts, h = 36),\n            series = \"Naïve\", PI = FALSE) +\n  autolayer(snaive(controlled_pos_ts, h = 36),\n            series = \"SNaïve\", PI = FALSE) +\n  autolayer(rwf(controlled_pos_ts, h = 36, drift = TRUE),\n              series = \"Drift\", PI = FALSE) +\n  autolayer(forecast(model_fit, 36),\n            series = \"Fit\", PI = FALSE) +\n  guides(color = guide_legend(title = \"Forecast\"))\n```\n\nThis model appears to be better than SNaïve as it does a better job of capturing the trend.\n\nSNaïve model error measurements:\n\n```{r, echo = FALSE}\naccuracy(snaive(controlled_pos_ts, h = 36))\n```\n\nFitted model error measurements:\n\n```{r, echo = FALSE}\nsummary(model_fit)\nsummary(auto_model)\n```\n\nThe model error measurements the model are all much lower than the SNaïve benchmark method.\n\n```{r, echo = FALSE}\nmodel_fit %>% forecast %>% autoplot()\n```\n\n# Marijuana Possession\n\nWe are fitting a SARIMA model as we saw a clear seasonal component in the previous section. We need to determine the following parameters:\n\n-   p: The order of AR terms.\n-   d: The degree of differencing needed to make the data stationary.\n-   q: The order of MA terms.\n-   P: The seasonal order of AR terms.\n-   D: The seasonal degree of differencing.\n-   Q: The seasonal order of MA terms.\n-   s: The seasonal period.\n\n## ACF and PACF\n\n```{r}\nggtsdisplay(marijuana_pos_ts)\n```\n\n## First Difference\n\n```{r, echo=FALSE}\nmarijuana_pos_ts %>% diff %>% ggtsdisplay()\n```\n\nThere still looks to be a trend at this level, we should try to difference one more time. We should also try a seasonal differencing at a seasonal period of 12. \n\n## Second Difference\n```{r}\nmarijuana_pos_ts %>% diff() %>% diff() %>% ggtsdisplay()\n```\n\nThis looks more stationary, we should determine parameters to try from here. \n\nThe seasonal period `s` is clearly 12. There are spikes at 1 and 4 on the ACF plot and spikes at 1, 2, and 4 on the PACF plot. Seasonal spikes occur at 1, 2, and 3 on the ACF plot, and 1 on the PACF plot.\n\n## Seasonal Difference\n\n```{r, echo=FALSE}\nmarijuana_pos_ts %>% diff(12) %>% ggtsdisplay()\n```\n\nThis looks less stationary than a simple first differencing, we will try `D` = 0 and 1.\n\nWe will try the following parameters:\n\n-   p: 1, 2, 4\n-   d: 1, 2\n-   q: 1, 4\n-   P: 1\n-   D: 0, 1\n-   Q: 1, 2, 3\n\n## Build Model\n\n```{r, echo=FALSE}\ni <- 1\n\ntemp <- data.frame()\nls <- matrix(rep(NA,9*32), nrow=32)\n\nfor(p in c(1,2,4)){\n  for(q in c(1,4)){\n    for(d in c(1,2)){\n      for(P in c(1)){\n        for(Q in c(1,2,3)){\n          for(D in c(0,1)){\n            if(p + d + q + P + D + Q<= 9){\n              model <- Arima(marijuana_pos_ts, order = c(p, d, q), seasonal = c(P, D, Q))\n              ls[i,] <- c(p, d, q, P, D, Q, model$aic, model$bic, model$aicc)\n              i <- i + 1\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\ntemp <- as.data.frame(ls)\nnames(temp) <- c(\"p\",\"d\",\"q\",\"P\", \"D\", \"Q\", \"AIC\",\"BIC\",\"AICc\")\n```\n\n## Model Selection and Diagnostics\n\n### Minimum AIC\n\n```{r, echo=FALSE}\nkable(temp[which.min(temp$AIC),])\n```\n\n### Minimum BIC\n\n```{r, echo = FALSE}\nkable(temp[which.min(temp$BIC),])\n```\n\n### Minimum AICc\n\n```{r, echo = FALSE}\nkable(temp[which.min(temp$AICc),])\n```\n\nIt is clear that the best model is one with parameters $p=1, d=1, q=1, P=1, D=1, Q=1$. We now check the model diagnostics.\n\n```{r  echo = FALSE}\nset.seed(621)\nmodel_output <- capture.output(sarima(marijuana_pos_ts, 1, 1, 1, 1, 1, 1, 12))\n```\n\nThe Ljung-Box statistic p-values suggest that there is no correlation between residuals at some lag values, meaning we have a good enough model. We will proceed with the model SARIMA(1, 1, 1)(1, 1, 1)12.\n\n### Auto-Arima\n\n```{r, echo = FALSE}\nauto_model <- auto.arima(marijuana_pos_ts)\nauto_model\n```\n\nThe information criteria are all slightly better than the previously used model of SARIMA(1, 1, 1)(1, 1, 1)12, but not so much better that this model would be worth considering moving forward.\n\n### Fitted vs. Actual\n\n```{r, echo=FALSE}\nmodel_fit <- Arima(marijuana_pos_ts, order = c(1, 1, 1), seasonal = c(1, 1, 1))\nplot(marijuana_pos_ts, col = \"blue\")\nlines(fitted(model_fit), col = \"green\")\nlegend(x = \"topright\", legend = c(\"marijuana_pos_ts\", \"fit1\"), fill = 4:1)\n```\n\nThe fitted model looks similar to the actual time series.\n\n## Seasonal Cross Validation\n\n1 step ahead and 12 steps ahead\n\n## Forecasting\n\n```{r, echo=FALSE}\nautoplot(marijuana_pos_ts) +\n  autolayer(meanf(marijuana_pos_ts, h = 36),\n            series = \"Mean\", PI = FALSE) +\n  autolayer(naive(marijuana_pos_ts, h = 36),\n            series = \"Naïve\", PI = FALSE) +\n  autolayer(snaive(marijuana_pos_ts, h = 36),\n            series = \"SNaïve\", PI = FALSE) +\n  autolayer(rwf(marijuana_pos_ts, h = 36, drift = TRUE),\n              series = \"Drift\", PI = FALSE) +\n  autolayer(forecast(model_fit, 36),\n            series = \"Fit\", PI = FALSE) +\n  guides(color = guide_legend(title = \"Forecast\"))\n```\n\nThis model appears to be better than SNaïve as it does a better job of capturing the trend.\n\nSNaïve model error measurements:\n\n```{r, echo = FALSE}\naccuracy(snaive(marijuana_pos_ts, h = 36))\n```\n\nFitted model error measurements:\n\n```{r, echo = FALSE}\nsummary(model_fit)\nsummary(auto_model)\n```\n\nThe model error measurements the model are all much lower than the SNaïve benchmark method.\n\n```{r, echo = FALSE}\nmodel_fit %>% forecast %>% autoplot()\n```\n\nIt doesn't really make sense to forecast here as we can be sure that there will be no more arrests for marijuana possession, but it is good to know that we have fitted a good model. We can predict what would have happened to the level of arrests if the policy changes that were instituded over the years never happened. \n\n# Motor Vehicle Theft\n\nWe are fitting an ARIMA model as we did not see a clear seasonal component in the previous section. We need to determine the following parameters:\n\n-   p: The order of AR terms.\n-   d: The degree of differencing needed to make the data stationary.\n-   q: The order of MA terms.\n\n## ACF and PACF\n\n```{r}\nggtsdisplay(motor_theft_ts)\n```\n\n## First Difference\n\n```{r, echo=FALSE}\nmotor_theft_ts %>% diff %>% ggtsdisplay()\n```\n\nThis looks to be slightly more stationary than the original series, we can proceed with the model build process. There are spikes at 1 and 3 on the ACF plot and spikes at 1, 2 on the PACF plot. \n\nWe will try the following parameters:\n\n-   p: 1, 2\n-   d: 0, 1\n-   q: 1, 3\n\n## Build Model\n\n```{r, echo=FALSE}\ni <- 1\n\ntemp <- data.frame()\nls <- matrix(rep(NA,6*8), nrow=8)\n\nfor(p in c(1,2)){\n  for(q in c(1,3)){\n    for(d in c(0,1)){\n      if(p + d + q <= 8){\n        model <- Arima(motor_theft_ts, order = c(p, d, q))\n        ls[i,] <- c(p, d, q, model$aic, model$bic, model$aicc)\n        i <- i + 1\n      }\n    }\n  }\n}\n\ntemp <- as.data.frame(ls)\nnames(temp) <- c(\"p\",\"d\",\"q\", \"AIC\",\"BIC\",\"AICc\")\n```\n\n## Model Selection and Diagnostics\n\n### Minimum AIC\n\n```{r, echo=FALSE}\nkable(temp[which.min(temp$AIC),])\n```\n\n### Minimum BIC\n\n```{r, echo = FALSE}\nkable(temp[which.min(temp$BIC),])\n```\n\n### Minimum AICc\n\n```{r, echo = FALSE}\nkable(temp[which.min(temp$AICc),])\n```\n\nIt is clear that the best model is one with parameters $p=2, d=1, q=3$. We now check the model diagnostics.\n\n```{r  echo = FALSE}\nset.seed(621)\nmodel_output <- capture.output(sarima(motor_theft_ts, 2, 1, 3))\n```\n\nThe Ljung-Box statistic p-values suggest that there may be correlation between residuals at some lag values, meaning we might not have a good enough model. We will still proceed with the model ARIMA(2, 1, 3).\n\n### Auto-Arima\n\n```{r, echo = FALSE}\nauto_model <- auto.arima(motor_theft_ts)\nauto_model\n```\n\nThe information criteria are all slightly better than the previously used model of ARIMA(2, 1, 3), and it considers the seasonal component, so this model would be worth considering moving forward.\n\n### Fitted vs. Actual\n\n```{r, echo=FALSE}\nmodel_fit <- Arima(motor_theft_ts, order = c(2, 1, 3))\nplot(motor_theft_ts, col = \"blue\")\nlines(fitted(model_fit), col = \"green\")\nlines(fitted(auto_model), col = \"red\")\nlegend(x = \"topright\", legend = c(\"motor_theft_ts\", \"fit1\", \"auto_fit\"), fill = 4:1)\n```\n\nThe fitted model and auto mdoel look similar to the actual time series.\n\n## Seasonal Cross Validation\n\n1 step ahead and 12 steps ahead\n\n## Forecasting\n\n```{r, echo=FALSE}\nautoplot(motor_theft_ts) +\n  autolayer(meanf(motor_theft_ts, h = 36),\n            series = \"Mean\", PI = FALSE) +\n  autolayer(naive(motor_theft_ts, h = 36),\n            series = \"Naïve\", PI = FALSE) +\n  autolayer(snaive(motor_theft_ts, h = 36),\n            series = \"SNaïve\", PI = FALSE) +\n  autolayer(rwf(motor_theft_ts, h = 36, drift = TRUE),\n              series = \"Drift\", PI = FALSE) +\n  autolayer(forecast(model_fit, 36),\n            series = \"Fit\", PI = FALSE) +\n  autolayer(forecast(auto_model, 36),\n            series = \"Auto Fit\", PI = FALSE) +\n  guides(color = guide_legend(title = \"Forecast\"))\n```\n\nBoth models appear to be better than SNaïve as they does a better job of capturing the trend. It is hard to tell which is better between the fit and the auto fit. \n\nSNaïve model error measurements:\n\n```{r, echo = FALSE}\naccuracy(snaive(motor_theft_ts, h = 36))\n```\n\nFitted model error measurements:\n\n```{r, echo = FALSE}\nsummary(model_fit)\nsummary(auto_model)\n```\n\nThe model error measurements the model are all much lower than the SNaïve benchmark method. The seasonal, auto fitted model slightly outperforms the non-seasonal ARIMA model, so we will go with that model. \n\n```{r, echo = FALSE}\nauto_model %>% forecast %>% autoplot()\n```\n\n# Murder\n\nWe are fitting an ARIMA model as we did not see a clear seasonal component in the previous section. We need to determine the following parameters:\n\n-   p: The order of AR terms.\n-   d: The degree of differencing needed to make the data stationary.\n-   q: The order of MA terms.\n\n## ACF and PACF\n\n```{r}\nggtsdisplay(murder_ts)\n```\n\n## First Difference\n\n```{r, echo=FALSE}\nmurder_ts %>% diff %>% ggtsdisplay()\n```\n\nThis looks to be much more stationary than the original series, we can proceed with the model build process. There are spikes at 1 on the ACF plot and spikes at 1 and 2 on the PACF plot. \n\nWe will try the following parameters:\n\n-   p: 1\n-   d: 0, 1\n-   q: 1, 2\n\n## Build Model\n\n```{r, echo=FALSE}\ni <- 1\n\ntemp <- data.frame()\nls <- matrix(rep(NA,6*4), nrow=4)\n\nfor(p in c(1)){\n  for(q in c(1,2)){\n    for(d in c(0,1)){\n      if(p + d + q <= 8){\n        model <- Arima(murder_ts, order = c(p, d, q))\n        ls[i,] <- c(p, d, q, model$aic, model$bic, model$aicc)\n        i <- i + 1\n      }\n    }\n  }\n}\n\ntemp <- as.data.frame(ls)\nnames(temp) <- c(\"p\",\"d\",\"q\", \"AIC\",\"BIC\",\"AICc\")\n```\n\n## Model Selection and Diagnostics\n\n### Minimum AIC\n\n```{r, echo=FALSE}\nkable(temp[which.min(temp$AIC),])\n```\n\n### Minimum BIC\n\n```{r, echo = FALSE}\nkable(temp[which.min(temp$BIC),])\n```\n\n### Minimum AICc\n\n```{r, echo = FALSE}\nkable(temp[which.min(temp$AICc),])\n```\n\nIt is clear that the best model is one with parameters $p=1, d=1, q=2$. We now check the model diagnostics.\n\n```{r  echo = FALSE}\nset.seed(621)\nmodel_output <- capture.output(sarima(murder_ts, 1, 1, 2))\n```\n\nThe Ljung-Box statistic p-values suggest that there may be correlation between residuals at some lag values, meaning we might not have a good enough model. We will still proceed with the model ARIMA(1, 1, 2).\n\n### Auto-Arima\n\n```{r, echo = FALSE}\nauto_model <- auto.arima(murder_ts)\nauto_model\n```\n\nThe information criteria are all slightly better than the previously used model of ARIMA(1, 1, 2), but not so much better that this model would be worth considering moving forward.\n\n### Fitted vs. Actual\n\n```{r, echo=FALSE}\nmodel_fit <- Arima(murder_ts, order = c(1, 1, 2))\nplot(murder_ts, col = \"blue\")\nlines(fitted(model_fit), col = \"green\")\nlegend(x = \"topleft\", legend = c(\"murder_ts\", \"fit1\"), fill = 4:1)\n```\n\nThe fitted model and auto mdoel look similar to the actual time series.\n\n## Seasonal Cross Validation\n\n1 step ahead and 12 steps ahead\n\n## Forecasting\n\n```{r, echo=FALSE}\nautoplot(murder_ts) +\n  autolayer(meanf(murder_ts, h = 36),\n            series = \"Mean\", PI = FALSE) +\n  autolayer(naive(murder_ts, h = 36),\n            series = \"Naïve\", PI = FALSE) +\n  autolayer(snaive(murder_ts, h = 36),\n            series = \"SNaïve\", PI = FALSE) +\n  autolayer(rwf(murder_ts, h = 36, drift = TRUE),\n              series = \"Drift\", PI = FALSE) +\n  autolayer(forecast(model_fit, 36),\n            series = \"Fit\", PI = FALSE) +\n  guides(color = guide_legend(title = \"Forecast\"))\n```\n\nThe fitted model is better than SNaïve as they does a better job of capturing the trend.\n\nSNaïve model error measurements:\n\n```{r, echo = FALSE}\naccuracy(snaive(murder_ts, h = 36))\n```\n\nFitted model error measurements:\n\n```{r, echo = FALSE}\nsummary(model_fit)\n```\n\nThe model error measurements the model are all much lower than the SNaïve benchmark method.\n\n```{r, echo = FALSE}\nmodel_fit %>% forecast %>% autoplot()\n```\n\n# Robbery\n\nWe are fitting a SARIMA model as we saw a clear seasonal component in the previous section. We need to determine the following parameters:\n\n-   p: The order of AR terms.\n-   d: The degree of differencing needed to make the data stationary.\n-   q: The order of MA terms.\n-   P: The seasonal order of AR terms.\n-   D: The seasonal degree of differencing.\n-   Q: The seasonal order of MA terms.\n-   s: The seasonal period.\n\n## ACF and PACF\n\n```{r}\nggtsdisplay(robbery_ts)\n```\n\n## First Difference\n\n```{r, echo=FALSE}\nrobbery_ts %>% diff %>% ggtsdisplay()\n```\n\nThe series looks to be stationary here. We should also try a seasonal differencing at a seasonal period of 12. \n\nThe seasonal period `s` is clearly 12. There are spikes at 1 and 4 on the ACF plot and spikes at 1, 2, and 4 on the PACF plot. Seasonal spikes occur at 1, 2, and 3 on the ACF plot, and 1 on the PACF plot.\n\n## Seasonal Difference\n\n```{r, echo=FALSE}\nrobbery_ts %>% diff(12) %>% ggtsdisplay()\n```\n\nThis looks less stationary than a simple first differencing, we will try `D` = 0 and 1.\n\nWe will try the following parameters:\n\n-   p: 1, 2, 4\n-   d: 1\n-   q: 1, 4\n-   P: 1\n-   D: 0, 1\n-   Q: 1, 2, 3\n\n## Build Model\n\n```{r, echo=FALSE}\ni <- 1\n\ntemp <- data.frame()\nls <- matrix(rep(NA,9*19), nrow=19)\n\nfor(p in c(1,2,4)){\n  for(q in c(1,4)){\n    for(d in c(1)){\n      for(P in c(1)){\n        for(Q in c(1,2,3)){\n          for(D in c(0,1)){\n            if(p + d + q + P + D + Q<= 9){\n              tryCatch({\n                model <- Arima(robbery_ts, order = c(p, d, q), seasonal = c(P, D, Q))\n                ls[i,] <- c(p, d, q, P, D, Q, model$aic, model$bic, model$aicc)\n              }, error = function(err) {\n                cat(\"error: \", p, d, q, P, D, Q, \"\\n\")\n              }, finally = {\n                i <- i + 1\n              })\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\ntemp <- as.data.frame(ls)\nnames(temp) <- c(\"p\",\"d\",\"q\",\"P\", \"D\", \"Q\", \"AIC\",\"BIC\",\"AICc\")\n```\n\n## Model Selection and Diagnostics\n\n### Minimum AIC\n\n```{r, echo=FALSE}\nkable(temp[which.min(temp$AIC),])\n```\n\n### Minimum BIC\n\n```{r, echo = FALSE}\nkable(temp[which.min(temp$BIC),])\n```\n\n### Minimum AICc\n\n```{r, echo = FALSE}\nkable(temp[which.min(temp$AICc),])\n```\n\nIt is clear that the best model is one with parameters $p=1, d=1, q=1, P=1, D=1, Q=2$. We now check the model diagnostics.\n\n```{r, echo = FALSE}\nset.seed(621)\nmodel_output <- capture.output(sarima(robbery_ts, 1, 1, 1, 1, 1, 2, 12))\n```\n\nThe Ljung-Box statistic p-values suggest that there is no correlation between residuals, meaning we have a good enough model. We will proceed with the model SARIMA(1, 1, 1)(1, 1, 2)12.\n\n### Auto-Arima\n\n```{r, echo = FALSE}\nauto_model <- auto.arima(robbery_ts)\nauto_model\n```\n\nThe information criteria are all worse than the previously used model of SARIMA(1, 1, 1)(1, 1, 2)12, this model is not worth considering moving forward.\n\n### Fitted vs. Actual\n\n```{r, echo=FALSE}\nmodel_fit <- Arima(robbery_ts, order = c(1, 1, 1), seasonal = c(1, 1, 2))\nplot(robbery_ts, col = \"blue\")\nlines(fitted(model_fit), col = \"green\")\nlegend(x = \"topright\", legend = c(\"robbery_ts\", \"fit1\"), fill = 4:1)\n```\n\nThe fitted model looks similar to the actual time series.\n\n## Seasonal Cross Validation\n\n1 step ahead and 12 steps ahead\n\n## Forecasting\n\n```{r, echo=FALSE}\nautoplot(robbery_ts) +\n  autolayer(meanf(robbery_ts, h = 36),\n            series = \"Mean\", PI = FALSE) +\n  autolayer(naive(robbery_ts, h = 36),\n            series = \"Naïve\", PI = FALSE) +\n  autolayer(snaive(robbery_ts, h = 36),\n            series = \"SNaïve\", PI = FALSE) +\n  autolayer(rwf(robbery_ts, h = 36, drift = TRUE),\n              series = \"Drift\", PI = FALSE) +\n  autolayer(forecast(model_fit, 36),\n            series = \"Fit\", PI = FALSE) +\n  guides(color = guide_legend(title = \"Forecast\"))\n```\n\nThis model appears to be better than SNaïve as it does a better job of capturing the trend.\n\nSNaïve model error measurements:\n\n```{r, echo = FALSE}\naccuracy(snaive(robbery_ts, h = 36))\n```\n\nFitted model error measurements:\n\n```{r, echo = FALSE}\nsummary(model_fit)\n```\n\nThe model error measurements the model are all much lower than the SNaïve benchmark method.\n\n```{r, echo = FALSE}\nmodel_fit %>% forecast %>% autoplot()\n```\n\n\n\n:::\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":false,"output-file":"arma_arima_sarima_models.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","editor":"visual","theme":"litera","fontsize":"1em","title":"ARMA/ARIMA/SARIMA Models","editor_options":{"chunk_output_type":"inline"}},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}